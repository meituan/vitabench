name: sliding_window_eval_no_rubrics_eval_template
chinese: |-
  # 系统信息
  {env_info}

  # 用户完整指令
  {user_instruction}

  # 背景说明
  - 这是一个user与assistant之间的对话场景，其中assistant可以调用工具获取信息和完成操作，工具返回结果将以tool开头
  - 你需要评估用户指令是否被完成
  - 由于对话轮次较多，我们采用滑动窗口评估法，即每次可见10轮对话，每个窗口间有2轮对话重叠
  - 你正在评估第 {window_idx} 个窗口（本次任务总共 {total_windows} 个窗口）
  - <window_content>包含了当前窗口的对话内容
  - <memory>包含了对之前窗口信息的记忆总结
  - <current_evaluation>包含了之前窗口的评估结果

  # 任务
  - 基于当前窗口的对话内容，判断用户完整指令中的需求是否都被满足
  - 你可以将状态由false更新为true，当且仅当assistant在此窗口和历史窗口完成了用户完整指令
  - 你也可以将true再次更新为false，当且仅当assistant在此窗口中推翻了之前的正确结论（但请注意：如果是用户需求自己发生了变更，例如下单后主动取消，则不应推翻原本对下单需求的评估）
  - 你可以参考“用户完整指令”来获取当前对话窗口的进度，避免出现不必要的修改
  - 将当前窗口内容<window_content>和记忆总结内容<memory>合并，并根据注意事项中的规则调整memory内容后作为新的<memory>输出
  
  # 注意事项
  - 重要：所有的评估以assistant的回复及工具调用请求是否完成用户指令为准，user在对话中表达的内容仅视为对assistant的提示和引导，不会直接影响评估标准，一切以用户指令为准！
  - 重要：查询类tool返回的结果仅对assistant可见，并不代表assistant对用户推荐的内容，因此也不直接影响评估结果，一切都要以assistant获取信息后对用户的回复为准！同时需要注意，Assistant 也不能编造 Tool 的返回结果！
  - 重要：对于购买类指令（涉及到订单细节，必须生成订单的），必须确认assistant是否真的完成了下单操作。有可能assistant误以为完成了下单操作，实际上工具调用失败；或user表示可以“可以自己下单”等情况，都应视为未满足要求
  - 对于涉及到订单细节如商品数量、送达时间的用户指令，必须严格满足原始用户指令要求（不能有商品数量偏差，不得晚于期望送达时间），用户妥协行为不影响评判结果（例如user表示“某商品少点也行”、“对订单内容没有异议”或“晚点送达也行”等），这类情况仍应视为未满足要求
  - 对于涉及到文本内容匹配的地址或订单备注类的用户指令，采用功能等效原则：只要实际内容能实现相同功能（如大致定位配送地点或传达顾客的主要需求），即使表述不完全一致或缺少部分细节，也视为满足要求
  - 对用户完整指令做适当分解，并评估每个子需求是否被满足：
    - 如果当前窗口没有涉及某个子需求，则记录当前没有涉及；
    - 如果当前窗口涉及某个子需求但无法完全决定，则将关键信息记录在memory中留待后续判断
    - 在memory中记录与子需求有关的关键信息及其对应的轮次[x]，以便后续窗口继续判断

  # 格式要求
  - 你的回复应为一个JSON对象，包含以下字段：
  - `justification`：对评估结果的简要解释
  - `meetExpectation`：评估结果（true或false）
 
  # 示例输入结构：
  <window_content>xxx</window_content>
  <memory>xxx</memory>
  <current_evaluation>xxx</current_evaluation>

  # 示例回复结构：
  ```json
  {{
      "memory": <对之前窗口信息的总结>,
      "justification": "<对评估结果的简要解释>",
      "meetExpectation": <true or false>
  }}
  ```

english: |-
  # System Information
  {env_info}

  # User Complete Instruction
  {user_instruction}

  # Background
  - This is a conversation scenario between a user and an assistant, where the assistant can call tools to retrieve information and complete operations. Tool return results will start with "tool"
  - You need to evaluate whether the user instruction has been completed
  - Due to the large number of conversation turns, sliding window evaluation is used, where each window shows 10 conversation turns with 2 overlapping turns between windows
  - You are evaluating window {window_idx} (out of {total_windows} windows total)
  - <window_content> contains the conversation content for the current window
  - <memory> contains a summary of information from previous windows
  - <current_evaluation> contains the evaluation results from previous windows

  # Task
  - Based on the conversation content in the current window, determine whether all requirements in the user's complete instruction have been met
  - You can update the status from false to true, if and only if the assistant has completed the user's complete instruction in this window and historical windows
  - You can also update true back to false, if and only if the assistant overturned a previous correct conclusion in this window (but note: if the user's needs themselves changed, such as actively canceling after placing an order, the original evaluation of the ordering requirement should not be overturned)
  - You can refer to the "User Complete Instruction" to understand the progress of the current conversation window and avoid unnecessary modifications
  - Merge the current window content <window_content> and memory summary content <memory>, and output as the new <memory> after adjusting memory content according to the rules in the notes
  
  # Important Notes
  - Important: All evaluations are based on whether the assistant's responses and tool call requests complete the user instruction. User expressions in the conversation are only considered as guidance for the assistant and do not directly affect evaluation standards. Everything is based on the user instruction!
  - Important: Query tool return results are only visible to the assistant and do not represent content recommended by the assistant to users, so they do not directly affect evaluation results either. Everything must be based on the assistant's responses to users after obtaining information! Also note that Assistant cannot fabricate Tool return results!
  - Important: For purchase instructions (involving order details that must generate orders), must confirm whether the assistant actually completed the ordering operation. The assistant may mistakenly believe they completed the ordering operation when in fact the tool call failed; or situations where the user states they "can place the order themselves," etc., should all be considered as not meeting the requirements
  - For user instructions involving order details such as product quantity or delivery time, must strictly meet the original user instruction requirements (no deviation in product quantities, delivery must not be later than the expected time). User compromise behavior does not affect evaluation results (for example, when a user states "fewer items is okay", "I have no objections to the order content" or "later delivery is fine" etc.). These situations should still be considered as not meeting the requirements
  - For user instructions involving text content matching of addresses or order notes, apply the functional equivalence principle: as long as the actual content can achieve the same function (such as roughly locating the delivery location or conveying the customer's main needs), it is considered to meet the requirements even if the expression is not completely consistent or lacks some details
  - Break down the user's complete instruction appropriately and evaluate whether each sub-requirement is met:
    - If the current window does not involve a certain sub-requirement, record that it is not involved;
    - If the current window involves a certain sub-requirement but cannot be fully determined, record key information in memory for future judgment
    - Record key information related to sub-requirements and their corresponding round [x] in memory for future window evaluation

  # Format Requirements
  - Your response should be a JSON object containing the following fields:
  - `justification`: brief explanation of the evaluation result
  - `meetExpectation`: evaluation result (true or false)
 
  # Example Input Structure:
  <window_content>xxx</window_content>
  <memory>xxx</memory>
  <current_evaluation>xxx</current_evaluation>

  # Example Response Structure:
  ```json
  {{
      "memory": <summary of previous window information>,
      "justification": "<brief explanation of the evaluation result>",
      "meetExpectation": <true or false>
  }}
  ```
